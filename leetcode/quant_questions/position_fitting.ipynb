{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting parameters \n",
    "np.random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "num_instruments = 10\n",
    "num_obs_insample = 200  # In-sample observations\n",
    "num_obs_outsample = 100  # Out-of-sample observations\n",
    "\n",
    "betas = np.random.uniform(0.5, 1.5, size=num_instruments)\n",
    "factor_exposure = np.random.uniform(-1, 1, size=num_obs_insample + num_obs_outsample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(num_instruments,num_obs):\n",
    "    # Generate alphas Z1 and Z2\n",
    "    Z1 = np.random.uniform(-0.5, 0.5, size=(num_obs, num_instruments))\n",
    "    Z2 = np.random.uniform(-0.5, 0.5, size=(num_obs, num_instruments))\n",
    "    risk_factor = factor_exposure[:num_obs]\n",
    "    errors = np.random.normal(0, 0.05, size=(num_obs, num_instruments))\n",
    "\n",
    "    # Calculate returns\n",
    "    returns = (\n",
    "        risk_factor[:, np.newaxis] +\n",
    "        Z1 / betas +\n",
    "        errors\n",
    "    )\n",
    "    # Create in-sample and out-of-sample DataFrames\n",
    "    columns = ['instrument', 'Z1', 'Z2', 'riskFactor', 'return']\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'instrument': np.tile(np.arange(num_instruments), num_obs),\n",
    "        'Z1': Z1.flatten(),\n",
    "        'Z2': Z2.flatten(),\n",
    "        'riskFactor': np.repeat(risk_factor, num_instruments),\n",
    "        'return': returns.flatten()\n",
    "    })\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_sample_df = generate_dataset(num_instruments,num_obs_insample)\n",
    "out_sample_df = generate_dataset(num_instruments,num_obs_outsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology \n",
    "Follow a two step linear regression approach  \n",
    "1. **Regreess `returns` on `risk_factor` to estimate the risk factor sensitivity or $\\beta$**\n",
    "$$ R_i = \\beta_f \\cdot F + \\epsilon$$\n",
    "_vectorized_:\n",
    "$$ \\beta = (X ^\\top X)^{-1}X^\\top y$$\n",
    "as: `beta = np.linalg.inv(X.T @ X) @ X.T @ y`\n",
    "2. **Estimate alpha contribution**  \n",
    "Regress residuals obtained from the first regression on the alpha columns: idio risk \n",
    "$$ \\epsilon = \\gamma_1 \\cdot Z1 + \\gamma_2 \\cdot Z2 + \\eta $$\n",
    "\n",
    "The gamma returns are the coefficents for the alphas where position can be defined as \n",
    "$$ Position_i = \\gamma_1 \\cdot Z1_i + \\gamma_2 \\cdot Z2_i$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the design matrix (add a column of ones for the intercept)\n",
    "X = in_sample_df['riskFactor'].values.reshape(-1, 1) # assume intercept at 1 \n",
    "y = in_sample_df['return'].values\n",
    "\n",
    "# Compute betas using the closed-form solution\n",
    "beta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "#predict\n",
    "y_pred = X @ beta \n",
    "#get the resids\n",
    "residuals = y - y_pred\n",
    "\n",
    "#Second regression / regress the idio \n",
    "# Each column can correspond to a predictor\n",
    "X_2 = np.column_stack((in_sample_df['Z1'].values, in_sample_df['Z2'].values))\n",
    "y_2 = residuals \n",
    "gammas = np.linalg.inv(X_2.T @ X_2) @ X_2.T @ y_2\n",
    "\n",
    "positions = gammas[0] * in_sample_df['Z1'].values + gammas[1] * in_sample_df['Z2'].values\n",
    "positions_normalized = positions / np.sum(np.abs(positions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply to outofsample dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_outsample = gammas[0] * out_sample_df['Z1'].values + gammas[1] * out_sample_df['Z2'].values\n",
    "positions_outsample_normalized = positions_outsample / np.sum(np.abs(positions_outsample))\n",
    "portfolio_returns = positions_outsample_normalized * out_sample_df['return'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize on sharpe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_return = np.mean(portfolio_returns)\n",
    "std_return = np.std(portfolio_returns)\n",
    "sharpe = mean_return / std_return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sharpe(gammas):\n",
    "    #reuse outofsample values\n",
    "    positions_outsample = gammas[0] * out_sample_df['Z1'].values + gammas[1] * out_sample_df['Z2'].values \n",
    "    positions_outsample_normalized = positions_outsample / np.sum(np.abs(positions_outsample))\n",
    "    portfolio_returns = positions_outsample_normalized * out_sample_df['return'].values\n",
    "    mean_return = np.mean(portfolio_returns)\n",
    "    std_return = np.std(portfolio_returns)\n",
    "    return - mean_return / std_return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize \n",
    "\n",
    "initial_gammas = gammas\n",
    "\n",
    "result = minimize(negative_sharpe, initial_gammas,method='Nelder-Mead')\n",
    "optimized_gammas = result.x\n",
    "\n",
    "#positions \n",
    "\n",
    "optimized_positions = optimized_gammas[0] * out_sample_df['Z1'].values + optimized_gammas[1] * out_sample_df['Z2'].values \n",
    "optimized_positions_normalized = optimized_positions / np.sum(np.abs(optimized_positions))\n",
    "optimized_portfolio_returns = optimized_positions_normalized * out_sample_df['return'].values\n",
    "optimized_mean_return = np.mean(optimized_portfolio_returns)\n",
    "optimized_std_return = np.std(optimized_portfolio_returns)\n",
    "optimized_sharpe = optimized_mean_return / optimized_std_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feel correct since the alphas are randomized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45385491285115237"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_sharpe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
