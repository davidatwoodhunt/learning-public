{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "Your task is to build a model to forecast the vector Y using the variables in X and Z.   \n",
    "You can assume that the conditional expectation of Y given X is linear in X. \n",
    "\n",
    "1.\tExamine and present the main characteristics of the data.\n",
    "2.\tPropose a forecasting model for Y only using the variables in X without Z and explain its properties.\n",
    "3.\tFurther improve the modeling from (2) with both X and Z.\n",
    "4.\tEvaluate the quality of your models and of their parameter estimates. Which one produces the best forecast? Interpret why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions:\n",
    "  1. I'm assuming that the index is significant and going to key off of it that is to say index _n_ in df X corresponds to index _n_ in df Y\n",
    "  2. From analizing the data, I don't think it's time series as it doesn't look browninan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'learning-dGoUWU5y-py3.11 (Python 3.11.9)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/dhunt/.cache/pypoetry/virtualenvs/learning-dGoUWU5y-py3.11/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in datasets \n",
    "data_pth = 'interview_problem_sets/Aquatic/data/'\n",
    "X = pd.read_csv(data_pth + 'X.csv',index_col=0)\n",
    "Y = pd.read_csv(data_pth + 'Y.csv',index_col=0)\n",
    "Z = pd.read_csv(data_pth + 'Z.csv',index_col=0)\n",
    "\n",
    "#fix dtype of columns from str to int\n",
    "X.columns = X.columns.astype(int)\n",
    "Y.columns = Y.columns.astype(int)\n",
    "Z.columns = Z.columns.astype(int) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values and describe the data\n",
    "print('========X========')\n",
    "display(X.info())\n",
    "display(X.describe())\n",
    "print('========Y========')\n",
    "display(Y.info())\n",
    "display(Y.describe())\n",
    "print('========Z========')\n",
    "display(Z.info())\n",
    "display(Z.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    " - There seems to be some missing datapoints in X that don't correspond to Y and Z \n",
    " - First task is cleaning the dataset to show some relationships between Y and Z \n",
    " - since the actual number of nulls are such a small part of the dataset, we will drop rather than trying to force to a condition\n",
    "   - important here too is to drop the corresponding index \n",
    "\n",
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show nulls\n",
    "display(X[X.isnull().any(axis=1)])\n",
    "# Y and Z are fine \n",
    "display(Y[Y.isnull().any(axis=1)])\n",
    "display(Z[Z.isnull().any(axis=1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for duplicates\n",
    "print('X duplicates:',X.duplicated().sum())\n",
    "print('Y duplicates:',Y.duplicated().sum())\n",
    "print('Z duplicates:',Z.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some exploratory plotting showing the main characteristicts of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to generate plots \n",
    "def plot_data(data, title):\n",
    "    # histogram\n",
    "    plt.figure(figsize=(10,5))\n",
    "    data.hist(bins=50, figsize=(10,10))\n",
    "    plt.suptitle(f\"{title} Histogram\", fontsize=16)\n",
    "    plt.show()\n",
    "    # boxplot\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.boxplot(data=data)\n",
    "    plt.suptitle(f\"{title} Boxplot\", fontsize=16)\n",
    "    plt.show()\n",
    "    # scatterplot\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.scatterplot(data=data)\n",
    "    plt.suptitle(f\"{title} Scatterplot\", fontsize=16)\n",
    "    # add key for the columns \n",
    "    plt.legend(title=title)\n",
    "    plt.show()\n",
    "    #corr matrix\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.heatmap(data.corr(), annot=True)\n",
    "    plt.suptitle(f\"{title} Correlation Matrix\", fontsize=16)\n",
    "    plt.show()\n",
    "    #pair plot \n",
    "    sns.pairplot(data)\n",
    "    plt.suptitle(f\"{title} Pairplot\", fontsize=16)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(X, 'X [pre cleaning]')\n",
    "# there seems to be some outliers in the data that we can clean up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed outliers by winsoring the data\n",
    "X_cleaned = X.clip(lower=X.quantile(0.01), upper=X.quantile(0.95), axis=1)\n",
    "# drop the index in y and z of the windsored data\n",
    "Y_cleaned = Y.loc[X_cleaned.index]\n",
    "Z_cleaned = Z.loc[X_cleaned.index]\n",
    "plot_data(X_cleaned, 'X [post cleaning]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes: \n",
    "- After removing outliers that seems to have improved the plotting significantly as we can see the more nuanced variance in the data set \n",
    "- of note is that in the scatterplot there seems to be some clear separation between the columns of the dataset possibly allowing for some explantion in the variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at Y \n",
    "plot_data(Y, 'Y')\n",
    "# corr and pairplot not necessary but included for completeness\n",
    "# Y seems cleaner with no outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting Model of Y based on X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_cleaned)\n",
    "# The data doesn't look brownian so i'm going to assume that its not time series \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y_cleaned, test_size=0.2, random_state=42)\n",
    "\n",
    "mean_prediction = np.mean(y_train)\n",
    "mse_baseline = mean_squared_error(y_test, [mean_prediction] * len(y_test))\n",
    "print(f'MSE of baseline (mean predictor): {mse_baseline}')\n",
    "# this needs a lot of work "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "- as this data is purely numeric with no hints as to the context i'm doing a broad selection on models to find the best MSE before I optimize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try a few different models\n",
    "from sklearn.ensemble import RandomForestRegressor # random forest\n",
    "from sklearn.neighbors import KNeighborsRegressor # knn (don't think this will work well but lets try it)\n",
    "from sklearn.svm import SVR \n",
    "from sklearn.linear_model import Lasso # l1\n",
    "from sklearn.linear_model import Ridge # l2 \n",
    "from sklearn.linear_model import ElasticNet # mixture\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline for each model\n",
    "pipelines = {\n",
    "    'rf': Pipeline([('rf', RandomForestRegressor(random_state=42))]),\n",
    "    'knn': Pipeline([('knn', KNeighborsRegressor())]),\n",
    "    'svr': Pipeline([('svr', SVR())]),\n",
    "    'lasso': Pipeline([('lasso', Lasso())]),\n",
    "    'ridge': Pipeline([('ridge', Ridge())]),\n",
    "    'elastic': Pipeline([('elastic', ElasticNet())]),\n",
    "    'gb': Pipeline([('gb', GradientBoostingRegressor())]),\n",
    "    'pca' : Pipeline([('pca', PCA()), ('rf', RandomForestRegressor(random_state=42))])\n",
    "}\n",
    "\n",
    "# create a parameter grid for each model\n",
    "param_grids = {\n",
    "    'rf': {'rf__n_estimators': [10, 100, 1000], 'rf__max_depth': [None, 5, 10, 15, 20], 'rf__min_samples_split': [2, 5, 10]},\n",
    "    'knn': {'knn__n_neighbors': [3, 5, 7, 9], 'knn__weights': ['uniform', 'distance']},\n",
    "    'svr': {'svr__C': [0.1, 1, 10], 'svr__kernel': ['linear', 'poly', 'rbf']},\n",
    "    'lasso': {'lasso__alpha': [0.1, 1, 10]},\n",
    "    'ridge': {'ridge__alpha': [0.1, 1, 10]},\n",
    "    'elastic': {'elastic__alpha': [0.1, 1, 10], 'elastic__l1_ratio': [0.1, 0.5, 0.9]},\n",
    "    'gb': {'gb__n_estimators': [10, 100, 1000], 'gb__learning_rate': [0.001, 0.01, 0.1], 'gb__max_depth': [3, 5, 7]},\n",
    "    'pca': {'pca__n_components': [2, 5, 10, 15, 20]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search on features and models \n",
    "feature_combinations = [\n",
    "    [0,1,2,3],\n",
    "    [0,1,2],\n",
    "    [0,1,3],\n",
    "    [0,2,3],\n",
    "    [1,2,3],\n",
    "    [0,1],\n",
    "    [0,2],\n",
    "    [0,3],\n",
    "    [1,2],\n",
    "    [1,3],\n",
    "    [2,3],\n",
    "    [0],\n",
    "    [1],\n",
    "    [2],\n",
    "    [3]\n",
    "]\n",
    "\n",
    "best_model = None\n",
    "best_mse = float('inf')\n",
    "best_features = None\n",
    "for features in feature_combinations:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled[:, features], Y_cleaned, test_size=0.2, random_state=42)\n",
    "    for model_name, pipeline in pipelines.items():\n",
    "        print(f\"Running GridSearchCV for {model_name} with features {features}\")\n",
    "        grid_search = GridSearchCV(pipeline, param_grids[model_name], cv=5, n_jobs=-1, verbose=1, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X_train, y_train.values.ravel()) # fits dimensionality better\n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        y_pred = grid_search.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        print(f\"Mean Squared Error: {mse}\")\n",
    "        print('=====================')\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_model = model_name\n",
    "            best_features = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled_feature_clip, y_train)\n",
    "    y_pred = model.predict(X_test_scaled[:,features])\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f'{name} MSE: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-4nU40dZu-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
